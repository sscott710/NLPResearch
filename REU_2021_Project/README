README

File Outline:
-Author information
-README file information
-Project description
-Operating Instructions
-Acknowledgements
-File Manifest and Description
-Known Bugs

Author of file and project: Savannah Scott; 2021 NSF REU EXERCISE student
Contact: sscott2@eagles.bridgewater.edu

README File Information:
This file is for the folder 'REU_Project', and all the items contained in it.
Note: note sheets with progress and other notes are in a Google Drive held by the author. Contact for more information.
If anything is confusing, needs to be added or edited, please contact the author.
Thank you for you're interest in this project!

Project Description:
Goal of this project: Use machine learning and text classification to idenify themes in historical documents (primarily The Federalist Papers)
Due to my interest in the digital humanities, I wanted to use the tools of computer science to help with the study of history. 
This project explores the use of artificial intelligence in the form of machine learning for identifying themes in historical documents.
The raw data of The Federalist Papers (obtained from Project Gutenberg) was broken up into individual essays.
To ceate the training data, 16 essays were broken up into docuements (sentences or phrases) and manually assigned 1 of 15 themes (I created the list of themes after an extensive literature review of the Federalist Papers).
The docuements from the training data has to be preprocessed and vectorized to be used by the machine learning models.
The machine learning models used in this project were algorithmic classifiers from sklearn, neural networks built from Keras, and ensemble classifiers from sklearn. Oversampling was also explored.
Once the model accuracy is suffieciently high, the goal is to use the models to evalaute the themes in the unlabeled Federalist Papers and perhaps other works from that time.
For more information on this project, please look at the project poster (project_Poster.pdf) found in this folder or contact the author of this file.

Operating Instructions:
All of this code for this project was written in Python.
To run any of the code, simply run the Python files in your preferred environment.
To use any of the models, they must be loaded into your Python environment and run.
To view or edit any of the data, simply use your preferred text editor.

Acknowledgements:
I want to thank my mentor Dr. Randall Cone (Department of Mathematical Sciences at Salisbury University) for all of his guidance.
This work was funded by NSF CCF-1757017 for the Explore Emerging Computing in Science and Engineering (EXERCISE) Reasearch Experience for Undergraduates (REU) at Salisbury University.

File Manifest and Description (all folders and files found within REU_Project):
***a brief description of each file and folder follows the name after the dash (-)
example: fileName - file information***
Class_Models - folder containing the saved algorithic classifier models
  linearsvc.sav - the saved LinearSVC model
  logreg.sav - the saved Logistic Regression model
  multiNB.sav - the saved Multinomial Niave Bayes model
  randForest.sav - the saved RandomForestClassifier model
Code - folder containing all the Python code used in this project
  analyticTool.py - makes or edits csv files to be analyzed by the models (for unlabeled data)
  beginning.py - very first effort of the project; explores preprocessing, tokenization, and finding simple statistics of a text
  hardCodeTheme.py - first attempt at token assignment; very simple rule based approach; ultimately a failure but learned from it
  makeSeparateEssays.py - creates separate text files for each Federalist Paper from the raw Project Gutenberg source
  model1.py - first attempt at a model; mainly used only for addTrainData() and eda() functions
  model2.py - use of pre-existing classification algorithmic models and ensemble classifiers
  model3.py - code for neural network model 1
  model4.py - starting code for neural network model 2; finished under model4n.py
  model4n.py - code for neural network model 2
  model5.py - code for neural network model 3
  model6.py - code for neural network models 4 and 5
  model7.py - code for neural network model 7
  model8.py - a neural network model attempt; does not work and was not explored further in this project
  modelParallel.py - where I would have implemented parallelism; did not have enough time so empty
  playingWithTopicModelling.py - incomplete code; saved and might come back to that strategy of topic modelling later
  topicModRough.py - exploring topic modelling with a single essay
  visualization.py - contains different ways to visualize data (training dataset, results, analytic results, etc)
glove.6B - Global Vectors for Word Representation; from Stanford; needed for model6.py; will not be describing each file
  glove.6B.50d.txt
  glove.6B.100d.txt
  glove.6B.200d.txt
  glove.6B.300d.txt
Graphs_and_Charts - contains pictures of graphs and charts made with Plotly
  paperPie.png - shows distribution of the number of documents from each essay in the training data
  stackedbarLegendClose.png - shows stacked bar graph of distrubution of theme in each paper with the legend on the left within the graph
  stackedbarLegendOutside.png - shows stacked bar graph of distrubution of theme in each paper with the legend on the right outside of the graph
  stackedBarTotal.png - first draft of file above
  themePie.png - shows the distribution of themes in the training data
  totalSunburst.png - a sunburst plot showing the themes in each essays
NN_Models - folder containing the saved neural network models
  model1.hdf5 - contains model from model3.py
  model2.hdf5 - contains model from model4n.py
  model3.hdf5 - contains model from model5.py
  model4.hdf5 - contains model from model6.py but the one with normal word embeddings
  model5.hdf5 - contains model from model6.py but the one with glove word embeddings
  model6.hdf5 - contains model from model7.py
papers - folder containing journal articles I found helpful for this project; will not be describing them as the title and abstract within the file both provide adequate descriptions
  A_Concise_Guide_to_the_Federalist_Papers_a_a_Source_of_the_Origi.pdf
  A_Method_for_Constructing_Supervised_Topic_Model_based_on_TF-ITF.pdf
  Bi-LSTM_Model_to_Increase_Acc_in_text_Class.pdf
  Dealing_with_Data_Imbalance_in_text_class.pdf
  Neural_Net_Approach_for_text_class_using_relevance_fator_as_term_weighing_method.pdf
  The_Order_of_Things_A_Study_on_Topic_Modelling_of_Literary_texts.pdf
  Thematic_Analysis_and_Visualization_of_textual_corpus.pdf
Raw_Data_Essays - folder containing each individual Federalist Paper essay; I will not describe each file (there's 85) but a simple Google search of the file names will lead you to information about that essay
  FEDERALIST No. 1.txt
  FEDERALIST No. 2.txt
  FEDERALIST No. 3.txt
  FEDERALIST No. 4.txt
  FEDERALIST No. 5.txt
  FEDERALIST No. 6.txt
  FEDERALIST No. 7.txt
  FEDERALIST No. 8.txt
  FEDERALIST No. 9.txt
  FEDERALIST No. 10.txt
  FEDERALIST No. 11.txt
  FEDERALIST No. 12.txt
  FEDERALIST No. 13.txt
  FEDERALIST No. 14.txt
  FEDERALIST No. 15.txt
  FEDERALIST No. 16.txt
  FEDERALIST No. 17.txt
  FEDERALIST No. 18.txt
  FEDERALIST No. 19.txt
  FEDERALIST No. 20.txt
  FEDERALIST No. 21.txt
  FEDERALIST No. 22.txt
  FEDERALIST No. 23.txt
  FEDERALIST No. 24.txt
  FEDERALIST No. 25.txt
  FEDERALIST No. 26.txt
  FEDERALIST No. 27.txt
  FEDERALIST No. 28.txt
  FEDERALIST No. 29.txt
  FEDERALIST No. 30.txt
  FEDERALIST No. 31.txt
  FEDERALIST No. 32.txt
  FEDERALIST No. 33.txt
  FEDERALIST No. 34.txt
  FEDERALIST No. 35.txt
  FEDERALIST No. 36.txt
  FEDERALIST No. 37.txt
  FEDERALIST No. 38.txt
  FEDERALIST No. 39.txt
  FEDERALIST No. 40.txt
  FEDERALIST No. 41.txt
  FEDERALIST No. 42.txt
  FEDERALIST No. 43.txt
  FEDERALIST No. 44.txt
  FEDERALIST No. 45.txt
  FEDERALIST No. 46.txt
  FEDERALIST No. 47.txt
  FEDERALIST No. 48.txt
  FEDERALIST No. 49.txt
  FEDERALIST No. 50.txt
  FEDERALIST No. 51.txt
  FEDERALIST No. 52.txt
  FEDERALIST No. 53.txt
  FEDERALIST No. 54.txt
  FEDERALIST No. 55.txt
  FEDERALIST No. 56.txt
  FEDERALIST No. 57.txt
  FEDERALIST No. 58.txt
  FEDERALIST No. 59.txt
  FEDERALIST No. 60.txt
  FEDERALIST No. 61.txt
  FEDERALIST No. 62.txt
  FEDERALIST No. 63.txt
  FEDERALIST No. 64.txt
  FEDERALIST No. 65.txt
  FEDERALIST No. 66.txt
  FEDERALIST No. 67.txt
  FEDERALIST No. 68.txt
  FEDERALIST No. 69.txt
  FEDERALIST No. 70.txt
  FEDERALIST No. 71.txt
  FEDERALIST No. 72.txt
  FEDERALIST No. 73.txt
  FEDERALIST No. 74.txt
  FEDERALIST No. 75.txt
  FEDERALIST No. 76.txt
  FEDERALIST No. 77.txt
  FEDERALIST No. 78.txt
  FEDERALIST No. 79.txt
  FEDERALIST No. 80.txt
  FEDERALIST No. 81.txt
  FEDERALIST No. 82.txt
  FEDERALIST No. 83.txt
  FEDERALIST No. 84.txt
  FEDERALIST No. 85.txt
  FedPapersOnlyEssays.txt - the file that houses all the essays together; was the source for the rest of the files in this folder
analyzeLinearSVC - csv file containing the labels (themes) for Federalist Paper 55 predicted by the LinearSVC model trained on the original dataset
analyzeRandFor - csv file containing the labels (themes) for Federalist Paper 55 predicted by the RandomForestClassifier model trained on the SMOTE training dataset 
project_Poster.pdf - poster for this project that provides all of the main details; an extension for the project description section
README - this current file providing the introductory information for this project folder
results - a file used to evalaute the results/accuracy of the model; essentially a note/scrap page
scrap2.txt - a scrap text file
sunBurstData - a csv file specifcally for constructing a sunburst plot; add to it in visualization.py
The_Federalist_Papers_from_ProjGuten.txt - raw data straight from Project Gutenberg
Tokenize.ipynb - code from the very beginning of the project; not important 
trainData - csv file containing the training data for the models
visData1 - csv file used to create the visualizations

Known Bugs:
model8.py does not work as there is a value error.
Confusion matrix in model3.py does not work but cuurently commented out

Thanks for reading!
